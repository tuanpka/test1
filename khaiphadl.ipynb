{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2092068,"sourceType":"datasetVersion","datasetId":539693},{"sourceId":41710976,"sourceType":"kernelVersion"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/pmtphamtuan/khaiphadl?scriptVersionId=254218333\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.offline as py\nfrom plotly.offline import iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport keras.layers as layers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T17:53:27.09604Z","iopub.execute_input":"2025-08-04T17:53:27.096338Z","iopub.status.idle":"2025-08-04T17:53:27.102541Z","shell.execute_reply.started":"2025-08-04T17:53:27.09632Z","shell.execute_reply":"2025-08-04T17:53:27.101841Z"}},"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"paths = ['/kaggle/input/meteonet/NW_Ground_Stations/NW_Ground_Stations/NW_Ground_Stations_2016.csv',\n         '/kaggle/input/meteonet/NW_Ground_Stations/NW_Ground_Stations/NW_Ground_Stations_2017.csv',\n         '/kaggle/input/meteonet/NW_Ground_Stations/NW_Ground_Stations/NW_Ground_Stations_2018.csv']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T17:53:31.459903Z","iopub.execute_input":"2025-08-04T17:53:31.460227Z","iopub.status.idle":"2025-08-04T17:53:31.463908Z","shell.execute_reply.started":"2025-08-04T17:53:31.460206Z","shell.execute_reply":"2025-08-04T17:53:31.463105Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"num_cols = ['height_sta','dd', 'ff', 'precip','hu', 'td', 't', 'psl']\ndtype = dict([(k,'float32') for k in num_cols])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T17:53:33.191452Z","iopub.execute_input":"2025-08-04T17:53:33.192205Z","iopub.status.idle":"2025-08-04T17:53:33.195789Z","shell.execute_reply.started":"2025-08-04T17:53:33.192177Z","shell.execute_reply":"2025-08-04T17:53:33.195104Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def open_csv(path:str):\n    df =  pd.read_csv(\n      path,\n      header = 0,\n      dtype = dtype\n  )\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T17:53:35.893353Z","iopub.execute_input":"2025-08-04T17:53:35.893709Z","iopub.status.idle":"2025-08-04T17:53:35.897984Z","shell.execute_reply.started":"2025-08-04T17:53:35.893678Z","shell.execute_reply":"2025-08-04T17:53:35.897295Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"weather_data = pd.concat((open_csv(_) for _ in paths))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T17:53:39.417157Z","iopub.execute_input":"2025-08-04T17:53:39.417768Z","iopub.status.idle":"2025-08-04T17:56:23.809983Z","shell.execute_reply.started":"2025-08-04T17:53:39.417737Z","shell.execute_reply":"2025-08-04T17:56:23.809277Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"weather_data.to_csv('weather_data.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T15:19:06.605062Z","iopub.execute_input":"2025-08-04T15:19:06.605364Z","iopub.status.idle":"2025-08-04T15:25:37.563673Z","shell.execute_reply.started":"2025-08-04T15:19:06.605342Z","shell.execute_reply":"2025-08-04T15:25:37.563107Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"weather_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T17:47:52.178593Z","iopub.execute_input":"2025-08-04T17:47:52.179302Z","iopub.status.idle":"2025-08-04T17:47:52.5152Z","shell.execute_reply.started":"2025-08-04T17:47:52.179274Z","shell.execute_reply":"2025-08-04T17:47:52.514143Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1744638310.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweather_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'weather_data' is not defined"],"ename":"NameError","evalue":"name 'weather_data' is not defined","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"weather_data = weather_data.loc[weather_data['lat']>48.4]\nweather_data = weather_data.loc[weather_data['lon']>-1.6]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"weather_data['date'] = pd.to_datetime(weather_data['date'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The weather dataset\nThe dataset contains 3 years of weather data collected from two main sources : ground stations and weather satellites. We'll build climate models which learn weather patterns from past observations and output one/multi timestep(s) forecasts. To limit latency we'll reduce the data space to approximately a quarter of the +60M observations reported in the dataset.These are weather parameters recorded by dozens of weather stations every 6 minutes from 2016 to 2018. We'll simplify the problem by training our models at the station level.\n\nInput features\n\nnumber_sta ----------> ground station ID\n\nlat : latitude ----------> decimal degrees (10-1 °)\n\nlon : longitude ----------> decimal degrees (10-1 °)\n\nheight_sta ----------> station height meters (m)\n\ndate ----------> a datetime object ('YYYY-MM-DD HH: mm :ss')\n\ndd ----------> Wind direction degrees (°)\n\nff ----------> Wind speed m.s-1\n\nprecip ----------> Precipitation during the reporting period kg.m2\n\nhu ----------> Humidity percentage (%)\n\ntd ----------> Dew point Kelvin (K)\n\nt ----------> Temperature Kelvin (K)\n\npsl ----------> Pressure reduced to sea level Pascal (Pa)","metadata":{}},{"cell_type":"code","source":"weather_data.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"weather_data.describe().round()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"weather_data['date'] = pd.to_datetime(weather_data['date'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"values = {_:np.mean(weather_data[_]) for _ in num_cols}\nweather_data = weather_data.fillna(value = values)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"weather_data.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"weather_data.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loc = weather_data['number_sta'].sample(1).values[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"station_id = np.unique(weather_data['number_sta'])\ncoordinates = [\n    [\n        np.mean(weather_data.loc[weather_data['number_sta'] == k,'lat']),\n        np.mean(weather_data.loc[weather_data['number_sta'] == k,'lon'])\n    ]\n                for k in station_id\n]\nstations = {k:v for k,v in zip(station_id,coordinates)}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"annual_rainfall = weather_data.groupby([weather_data['date'].dt.year,'number_sta'])['precip'].sum()\nannual_rainfall = annual_rainfall.reset_index(1).groupby('number_sta')['precip'].mean()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame(annual_rainfall)\ndf['lat'] = [stations[_][0] for _ in df.index]\ndf['lon'] = [stations[_][1] for _ in df.index]\nfig = px.scatter_mapbox(\n    df, lat='lat', lon='lon',\n    zoom = 6,\n    color = 'precip',\n    color_continuous_scale=px.colors.sequential.YlGnBu\n)\n\nprint('Average annual precipitation in mm')\nfig.update_layout(mapbox_style=\"carto-darkmatter\")\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.update_traces(marker_size=12)\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.reset_index(0)\ndf['height_sta'] = [weather_data.loc[weather_data['number_sta'] == _,'height_sta'].values[0] for _ in df['number_sta']]\ndf['Atm. pressure'] = [weather_data.loc[weather_data['number_sta'] == _,'psl'].values[0] for _ in df['number_sta']]\ndf['ff'] = weather_data.groupby([weather_data['date'].dt.year,'number_sta'])['ff'].mean().groupby('number_sta').mean().values\nfeatures = ['height_sta','Atm. pressure', 'ff']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"titles = [\"Height of Station\", \"Pressure Reduced to Sea Level\", \"Wind Speed\"]\n\nfig, axs = plt.subplots(2, 2, sharey=True, figsize=[8, 8])\n\n# Lặp qua các trục và các đặc trưng\nfor ax, i, title in zip(axs.flatten(), features, titles):\n    sns.scatterplot(data=df, x=i, y='precip', ax=ax)\n    ax.set_title(title)  # Đặt tiêu đề cho từng biểu đồ\n\n# Loại bỏ ô trống thừa (nếu có)\nplt.delaxes(axs[1, 1])\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def color_strong_corr(val):\n    color = 'red' if (abs(val) > 0.1) & (abs(val) <1.0) else 'black'\n    return 'color: %s' % color\ndf[['precip','height_sta','Atm. pressure','ff']].corr().\\\n    style.applymap(color_strong_corr)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features = ['height_sta', 'Atm. pressure', 'ff', 'precip']\n\n# Select only the columns of interest\ndf_features = df[features]\n\n# Calculate the correlation matrix\ncorr_matrix = df_features.corr()\n\n# Plot the correlation matrix using seaborn\nplt.figure(figsize=(10, 8))\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", vmin=-1, vmax=1, linewidths=0.5)\nplt.title('Correlation Matrix')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = weather_data.set_index('date')\ndf['t'] = df['t'] - 273.5","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig = px.line(df['2016-01-01':'2018-12-30'][['t','hu']].resample('D').mean(),\n             title = 'Temperature (°C) - Humidity ratio')\nfig.update_xaxes(\n    rangeslider_visible=True,\n    rangeselector=dict(\n        buttons=list([\n            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n            dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n            dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n            dict(step=\"all\")\n        ])\n    )\n)\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig = px.line(df['2016-01-01':'2018-12-30']['precip'].resample('7D').sum(),\n             title = 'Overall weekly precipitation')\nfig.update_xaxes(\n    rangeslider_visible=True\n)\nfig.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"jan_2018 = df['2018-01-03':'2018-01-03'].reset_index()\njan_2018['ff'] = jan_2018['ff'] * 3.6\njan_2017 = df['2017-01-03':'2017-01-03'].reset_index()\njan_2016 = df['2016-01-03':'2016-01-03'].reset_index()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig,axs = plt.subplots(1,2, figsize = (12,6))\njan_2018.groupby(jan_2018['date'].dt.hour)[\"ff\"].max().plot(kind = 'bar', rot=0,\n                                                 title = \"Max windspeed recorded 2018/01/03\",\n                                                 xlabel = 'Hour of the day',\n                                                 ylabel = 'Windspeed in km/h',\n                                                 ax = axs[0])\njan_2018.groupby(jan_2018['date'].dt.hour)[\"precip\"].mean().plot(kind = 'bar', rot=0,\n                                                 title = \"Avg Rainfall per station 2018/01/03\",\n                                                 xlabel = 'Hour of the day',\n                                                 ylabel = 'Precipitation in mm',\n                                                 ax = axs[1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = [jan_2018,jan_2017,jan_2016]\ntitle = [\"2018-01-03\",\"2017-01-03\",\"2016-01-03\"]\nfig, axs = plt.subplots(2,2, sharey = True, figsize = [10,10])\nfig.suptitle(\"Cumulative hourly precipitation\")\nfor ax,i,df,title in zip(axs.flatten(),features,df,title) :\n    df.groupby(df['date'].dt.hour)[\"precip\"].sum().cumsum().plot(kind = 'line',\n                             title = title,\n                             ylabel = 'Rainfall in mm',\n                             xlabel = 'Hours of the day',\n                             xticks = np.arange(0,26,2),\n                             ax =  ax\n                        )\nplt.delaxes(axs[1,1])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"date_range = pd.date_range(start= '2016-01-01', end = '2018-12-31',\n                          freq='D').strftime(\"%Y-%m-%d\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"init = time.time()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def daily_forecast(loc) :\n    df = weather_data.loc[weather_data['number_sta'] == loc]\n    df = df.set_index('date')\n    df['hours'] = [_.hour for _ in df.index]\n    df['days'] = [_.dayofyear for _ in df.index]\n    df['years'] = [_.year for _ in df.index]\n    \n   \n    df['3'] = df['hours']%3\n    df = df.loc[df['3'] == 0.0]\n    df = pd.concat([\n        df[_:_].drop_duplicates(subset = 'hours').reset_index(drop = True) for\n        _ in date_range\n                   ]\n    )\n    df = df[[\"height_sta\",\"dd\",\"ff\",\"precip\",\"hu\",\"td\",\"t\",\"hours\",\"days\",\"years\"]]\n    \n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features = [\"height_sta\",\"dd\",\"ff\",\"precip\",\"hu\",\"td\",\"t\",\"days\"]\ndays0 = np.arange(1,365,2)\ndays1 = np.arange(2,365,2)\nlen(days0) == len(days1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def _3h_windowing(df:pd.DataFrame) :\n    s_scaler = MinMaxScaler()\n    \n    days0 = np.arange(1,365,2)\n    days1 = np.arange(2,365,2)\n    X,y = [],[]\n    \n    for d0,d1 in zip(days0,days1) :\n        x = df.loc[df['days'] == d0]\n        z = df.loc[df['days'] == d1]\n        \n        if len(x) == len(z) :\n            X.append(x)\n            y.append(z)\n            \n    X = pd.concat(X)[features]\n    y =  pd.concat(y)[features]\n    \n    X = pd.DataFrame(s_scaler.fit_transform(X))\n    y = pd.DataFrame(s_scaler.fit_transform(y))\n        \n    return X,y, s_scaler","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def split_dataset(X:pd.DataFrame, y:pd.DataFrame) :\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, shuffle = True, random_state=42)\n    \n    X_train, X_val, y_train, y_val = train_test_split(\n    X_train, y_train, test_size=0.1, shuffle = True, random_state=7)\n    \n    return {\n        'train_set': tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(64).prefetch(2),\n        'val_set' : tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(64).prefetch(2),\n        'test_set' : [X_test, y_test]\n           }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def model_history(model:'o', train_metrics:str, val_metrics:str, loss:str):\n    plt.figure()\n    plt.xlabel('Epoch')\n    plt.ylabel(loss)\n    plt.plot(model.epoch, np.array(model.history[train_metrics]),\n           label='Train')\n    plt.plot(model.epoch, np.array(model.history[val_metrics]),\n           label = 'Val')\n    plt.legend()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = daily_forecast(loc)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**> Pyspark******","metadata":{}},{"cell_type":"code","source":"!pip install pyspark","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col\n\n# Initialize Spark session\nspark = SparkSession.builder.appName(\"WeatherForecasting\").getOrCreate()\n\nspark_df = spark.createDataFrame(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"spark_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pyspark.ml.feature import VectorAssembler, StandardScaler\nfrom pyspark.ml import Pipeline\n\n\nfeature_cols = [\"height_sta\", \"dd\", \"ff\", \"precip\", \"hu\", \"td\", \"hours\", \"days\", \"years\"]\n\nassembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n\n\npipeline = Pipeline(stages=[assembler])\n\n\ndf_transformed = pipeline.fit(spark_df).transform(spark_df)\n\n\ndf_transformed.select(\"features\").show(truncate=False)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_transformed","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Show transformed data\ndf_transformed.select(\"features\").show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the data into train, validation, and test sets\ntrain_set,test_set = df_transformed.randomSplit([0.8, 0.2], seed=1234)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_set","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_set","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pyspark.ml.regression import LinearRegression\n\n# Initialize the model\nlr = LinearRegression(featuresCol=\"features\", labelCol=\"t\")\n\n# Train the model\nlr_model = lr.fit(train_set)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Number of iterations: {lr_model.summary.totalIterations}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make predictions on the validation set\ntest_predictions = lr_model.transform(test_set)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions.select(\"prediction\", \"t\", \"features\").show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pyspark.ml.evaluation import RegressionEvaluator\n\n# Evaluate the model on validation set\nevaluator = RegressionEvaluator(labelCol=\"t\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(test_predictions)\nprint(f\"test_predictions RMSE: {rmse}\")\n\n# Evaluate the model on test set\ntest_predictions = lr_model.transform(test_set)\ntest_rmse = evaluator.evaluate(test_predictions)\nprint(f\"Test RMSE: {test_rmse}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions.toPandas()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot(test_predictions_pd,titel=\"Test Set: Actual vs Predicted Linear Regression\"): \n    plt.figure(figsize=(12, 6))\n    plt.plot(test_predictions_pd[\"t\"], label=\"Actual\")\n    plt.plot(test_predictions_pd[\"prediction\"], label=\"Predicted\")\n    plt.plot(test_predictions_pd[\"t\"] - test_predictions_pd[\"prediction\"], \n             label=\"Residual (Actual - Predicted)\", linestyle=\"--\")\n    plt.title(titel)\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Temperature\")\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pyspark.ml.regression import DecisionTreeRegressor, RandomForestRegressor\n\n\ndt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"t\")\n\n\ndt_model = dt.fit(train_set)\n\n\nrf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"t\")\n\n\nrf_model = rf.fit(train_set)\n\n\ndt_predictions = dt_model.transform(test_set)\nrf_predictions = rf_model.transform(test_set)\n\n\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\n\nevaluator = RegressionEvaluator(labelCol=\"t\", predictionCol=\"prediction\", metricName=\"rmse\")\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rf_feature_importances = pd.DataFrame({\n'feature': feature_cols,\n'importance': rf_model.featureImportances.toArray()\n}).sort_values('importance', ascending=False)\n\nplt.figure(figsize=(10, 6))\nplt.barh(rf_feature_importances['feature'], rf_feature_importances['importance'])\nplt.title('Mức độ quan trọng của các thuộc tính')\nplt.xlabel('Tầm quan trọng')\nplt.gca().invert_yaxis() # Hiển thị thuộc tính quan trọng nhất ở trên cùng\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dt_predictions.select(\"t\", \"prediction\").show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndt_rmse = evaluator.evaluate(dt_predictions)\nprint(f\"Decision Tree RMSE: {dt_rmse}\")\n\n\nrf_rmse = evaluator.evaluate(rf_predictions)\nprint(f\"Random Forest RMSE: {rf_rmse}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dt_predictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndt_predictions_pd = dt_predictions.select(\"t\", \"prediction\").toPandas()\nrf_predictions_pd = rf_predictions.select(\"t\", \"prediction\").toPandas()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ln_predictions_pd=test_predictions.select(\"t\", \"prediction\").toPandas()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dt_predictions_pd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndt_predictions_pd = dt_predictions.select(\"t\", \"prediction\").toPandas()\nrf_predictions_pd = rf_predictions.select(\"t\", \"prediction\").toPandas()\n\ndt_predictions_pd[\"residual\"] = dt_predictions_pd[\"t\"] - dt_predictions_pd[\"prediction\"]\nrf_predictions_pd[\"residual\"] = rf_predictions_pd[\"t\"] - rf_predictions_pd[\"prediction\"]\n\n\nplt.figure(figsize=(12, 6))\n\n\nplt.subplot(1, 2, 1)\nplt.scatter(dt_predictions_pd.index, dt_predictions_pd[\"residual\"], color='orange', alpha=0.5)\nplt.axhline(0, color='black', linewidth=1)\nplt.title(\"Residuals for Decision Tree\")\nplt.xlabel(\"Index\")\nplt.ylabel(\"Residual (Actual - Predicted)\")\n\n\nplt.subplot(1, 2, 2)\nplt.scatter(rf_predictions_pd.index, rf_predictions_pd[\"residual\"], color='blue', alpha=0.5)\nplt.axhline(0, color='black', linewidth=1)\nplt.title(\"Residuals for Random Forest\")\nplt.xlabel(\"Index\")\nplt.ylabel(\"Residual (Actual - Predicted)\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions_pd= test_predictions.select(\"t\", \"prediction\").toPandas()\ntest_predictions_pd[\"residual\"] = test_predictions_pd[\"t\"] - test_predictions_pd[\"prediction\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 2)\nplt.scatter(test_predictions_pd.index, test_predictions_pd[\"residual\"], color='red', alpha=0.5)\nplt.axhline(0, color='black', linewidth=1)\nplt.title(\"Residuals for LinearRegression\")\nplt.xlabel(\"Index\")\nplt.ylabel(\"Residual (Actual - Predicted)\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mae_evaluator = RegressionEvaluator(labelCol=\"t\", predictionCol=\"prediction\", metricName=\"mae\")\ndt_mae = mae_evaluator.evaluate(dt_predictions)\nrf_mae = mae_evaluator.evaluate(rf_predictions)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"r2_evaluator = RegressionEvaluator(labelCol=\"t\", predictionCol=\"prediction\", metricName=\"r2\")\ndt_r2 = r2_evaluator.evaluate(dt_predictions)\nrf_r2 = r2_evaluator.evaluate(rf_predictions)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Decision Tree Performance:\")\nprint(f\"RMSE: {evaluator.evaluate(dt_predictions)}\")\nprint(f\"MAE: {mae_evaluator.evaluate(dt_predictions)}\")\nprint(f\"R2: {r2_evaluator.evaluate(dt_predictions)}\")\n\n\nprint(\"\\nRandom Forest Performance:\")\nprint(f\"RMSE: {evaluator.evaluate(rf_predictions)}\")\nprint(f\"MAE: {mae_evaluator.evaluate(rf_predictions)}\")\nprint(f\"R2: {r2_evaluator.evaluate(rf_predictions)}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_fit.write().overwrite().save(\"models/Decision_Tree_model\")\nmodel_fit.write().overwrite().save(\"models/random_forest_model\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"r2_evaluator = RegressionEvaluator(labelCol=\"t\", predictionCol=\"prediction\", metricName=\"r2\")\n# dt_r2 = r2_evaluator.evaluate(test_predictions)\nprint(\"\\nLinear Regression Performance:\")\nprint(f\"RMSE: {evaluator.evaluate(test_predictions)}\")\nprint(f\"MAE: {mae_evaluator.evaluate(test_predictions)}\")\nprint(f\"R2: {r2_evaluator.evaluate(test_predictions)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nmodel_fit.write().overwrite().save(\"models/Linear_Regression_model\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}